name: Merge Rules from Multiple Sources

on:
  workflow_dispatch:
  schedule:
    - cron: '0 0 * * *'
  push:
    branches: [ main ]

jobs:
  merge-rules:
    runs-on: ubuntu-latest
    permissions:
      contents: write  # 添加写入权限
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.x'
        
    - name: Download and merge rules
      run: |
        # 创建合并脚本
        cat > merge_rules.py << 'EOF'
        #!/usr/bin/env python3
        import requests
        import re
        from urllib.parse import urlparse
        from datetime import datetime
        
        # 国内规则源列表
        china_rule_sources = [
            "https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/master/rule/Surge/China/China.list",
            "https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/master/rule/Surge/ChinaASN/ChinaASN.list"
            # 在这里添加更多国内规则源URL
        ]
        
        # 国外规则源列表
        proxy_rule_sources = [
            "https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/master/rule/Surge/Telegram/Telegram.list",
            "https://raw.githubusercontent.com/blackmatrix7/ios_rule_script/master/rule/Surge/YouTube/YouTube.list"
            # 在这里添加更多国外规则源URL
        ]
        # 支持的规则类型
        valid_rule_types = {
            'DOMAIN', 'DOMAIN-SUFFIX', 'DOMAIN-KEYWORD', 
            'IP-CIDR', 'IP-CIDR6', 'USER-AGENT', 'PROCESS-NAME', 'IP-ASN'
        }
        
        def is_valid_rule(line):
            line = line.strip()
            if not line or line.startswith('#'):
                return False
            parts = line.split(',')
            if len(parts) < 2:
                return False
            rule_type = parts[0].strip()
            return rule_type in valid_rule_types
        
        def download_rules(url):
            try:
                print(f"正在下载: {url}")
                response = requests.get(url, timeout=30)
                response.raise_for_status()
                return response.text
            except Exception as e:
                print(f"下载失败 {url}: {e}")
                return None
        
        def parse_rules(content, source_url):
            rules = set()
            lines = content.split('\n')
            for line in lines:
                if is_valid_rule(line):
                    rule = line.strip()
                    rules.add(rule)
            print(f"从 {source_url} 解析出 {len(rules)} 条规则")
            return rules
        
        def generate_rule_file(rules, filename, rule_type):
            sorted_rules = sorted(rules, key=lambda x: (
                list(valid_rule_types).index(x.split(',')[0]) if x.split(',')[0] in valid_rule_types else 999,
                x
            ))
            
            output_lines = []
            output_lines.append(f"# NAME: {rule_type} Rules")
            output_lines.append(f"# DESCRIPTION: {rule_type} rules merged from multiple sources")
            output_lines.append(f"# UPDATED: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            output_lines.append(f"# SOURCES: {len(rules)} unique rules")
            
            source_count = {}
            for rule in rules:
                rule_type = rule.split(',')[0]
                source_count[rule_type] = source_count.get(rule_type, 0) + 1
            
            for rule_type in sorted(valid_rule_types):
                if rule_type in source_count:
                    output_lines.append(f"# {rule_type}: {source_count[rule_type]}")
            
            output_lines.append(f"# TOTAL: {len(sorted_rules)}")
            output_lines.append("")
            output_lines.extend(sorted_rules)
            
            with open(filename, 'w', encoding='utf-8') as f:
                f.write('\n'.join(output_lines))
            
            print(f"{rule_type} 规则生成完成！总共 {len(sorted_rules)} 条规则")
        
        # 处理国内规则
        print("=== 开始处理国内规则 ===")
        china_rules = set()
        for source_url in china_rule_sources:
            content = download_rules(source_url)
            if content:
                rules = parse_rules(content, source_url)
                china_rules.update(rules)
        
        generate_rule_file(china_rules, 'china.list', 'China')
        
        # 处理国外规则
        print("=== 开始处理国外规则 ===")
        proxy_rules = set()
        for source_url in proxy_rule_sources:
            content = download_rules(source_url)
            if content:
                rules = parse_rules(content, source_url)
                proxy_rules.update(rules)
        
        generate_rule_file(proxy_rules, 'proxy.list', 'Proxy')
        
        print("所有规则处理完成！")
        EOF
        
        pip install requests
        python merge_rules.py
        
    - name: Check generated files
      run: |
        echo "检查生成的文件:"
        ls -la china.list proxy.list
        echo "china.list 前5行:"
        head -5 china.list
        echo "proxy.list 前5行:"
        head -5 proxy.list
        
    - name: Commit and push changes
      run: |
        git config --local user.email "github-actions[bot]@users.noreply.github.com"
        git config --local user.name "github-actions[bot]"
        
        git add china.list proxy.list
        
        if git diff --staged --quiet; then
          echo "没有检测到变化"
        else
          git commit -m "Auto-update rules: China $(wc -l < china.list) rules, Proxy $(wc -l < proxy.list) rules"
          git push
        fi
